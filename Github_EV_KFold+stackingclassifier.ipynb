{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"Green\"> This notebook is a comprehensive program used for data preprocesssing and build models for Predicting EV Buying Intention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= \"Indigo\">Project Team:\n",
    "<ol>\n",
    "  <font color= \"Indigo\"><li>Gayathri Shanmugam</li>\n",
    "  <li>Kayalvizhi Vellaichamy</li>\n",
    "  <li>Nitya Malladi</li>\n",
    "    <li>Saranya Anandan</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "The global auto manufacturing industry is undergoing rapid transformation by shifting focus from fuel-based vehicles to zero-emission vehicles (ZEVs). ZEVs are further categorized into battery electric vehicles and hydrogen fuel cell electric vehicles. In the United States, the federal government has mandated that at least 50% of the total cars sold should belong to the zero-emission category by the year 2030.\n",
    "The scope of this project is to build a predictive model which classifies EV buyers in the United States based on their socio-demographic characteristics and their views on the current EV ecosystem. As per a recent survey, 53% of American vehicle users continue to prefer the traditional fuel-based vehicles over electric vehicles.This is a concerning issue for the government, auto companies and their dealers, and needs to be addressed by classifying an EV buyer from a non-buyer. Once the non-buyers are identified, focused strategies can be implemented to convert them into EV buyers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mord import LogisticIT\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import neighbors \n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from dmba import classificationSummary, gainsChart, liftChart\n",
    "from dmba import adjusted_r2_score, AIC_score, BIC_score\n",
    "from dmba import regressionSummary, exhaustive_search \n",
    "from dmba import backward_elimination, forward_selection, stepwise_selection\n",
    "from dmba import plotDecisionTree, classificationSummary, regressionSummary\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bichoice  range  home_chg  work_chg  town  highway  gender          state  \\\n",
      "0         0      1         3         1     3        2       0  Massachusetts   \n",
      "1         0      4         3         3     4        2       0  Massachusetts   \n",
      "2         0      2         5         0     2        4       0  Massachusetts   \n",
      "3         0      4         5         0     1        1       0  Massachusetts   \n",
      "4         0      1         5         0     1        2       0  Massachusetts   \n",
      "5         0      3        20        10     2        4       0  Massachusetts   \n",
      "6         1      3         1         1     3        2       0  Massachusetts   \n",
      "7         0      1         3         3     4        2       0  Massachusetts   \n",
      "8         0      1         3         5     4        1       0  Massachusetts   \n",
      "9         0      2         5        20     3        4       0  Massachusetts   \n",
      "\n",
      "   Region  education  ...  home_parking  home_evse  work_parking  work_evse  \\\n",
      "0       1          4  ...             3          2             5          2   \n",
      "1       1          4  ...             3          2             5          2   \n",
      "2       1          4  ...             3          2             5          2   \n",
      "3       1          4  ...             3          2             5          2   \n",
      "4       1          4  ...             3          2             5          2   \n",
      "5       1          4  ...             3          2             5          2   \n",
      "6       1          4  ...             3          2             2          2   \n",
      "7       1          4  ...             3          2             2          2   \n",
      "8       1          4  ...             3          2             2          2   \n",
      "9       1          4  ...             3          2             2          2   \n",
      "\n",
      "   buycar  zipcode  dmileage  long_dist  Age_category  RUCA  \n",
      "0       3     1247        20          2             3     2  \n",
      "1       3     1247        20          2             3     2  \n",
      "2       3     1247        20          2             3     2  \n",
      "3       3     1247        20          2             3     2  \n",
      "4       3     1247        20          2             3     2  \n",
      "5       3     1247        20          2             3     2  \n",
      "6       2     1420        40          4             2     1  \n",
      "7       2     1420        40          4             2     1  \n",
      "8       2     1420        40          4             2     1  \n",
      "9       2     1420        40          4             2     1  \n",
      "\n",
      "[10 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create data frame for EV data set.\n",
    "EV_intention_df = pd.read_csv('AfterMerge_Dataset.csv')\n",
    "\n",
    "# Display the first 10 records of EV_intention_df data frame.\n",
    "print(EV_intention_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of dataframe: (5898, 27)\n"
     ]
    }
   ],
   "source": [
    "# Determine dimensions of dataframe. \n",
    "print('Dimensions of dataframe:',EV_intention_df.shape )\n",
    "# It has 5898 rows and 27 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EV_intention_df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bichoice        0\n",
       "range           0\n",
       "home_chg        0\n",
       "work_chg        0\n",
       "town            0\n",
       "highway         0\n",
       "gender          0\n",
       "state           0\n",
       "Region          0\n",
       "education       0\n",
       "employment      0\n",
       "hsincome        0\n",
       "hsize           0\n",
       "housit          0\n",
       "residence       0\n",
       "all_cars        0\n",
       "ev_cars         0\n",
       "home_parking    0\n",
       "home_evse       0\n",
       "work_parking    0\n",
       "work_evse       0\n",
       "buycar          0\n",
       "zipcode         0\n",
       "dmileage        0\n",
       "long_dist       0\n",
       "Age_category    0\n",
       "RUCA            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EV_intention_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data types of the columns for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes of all the columns in the dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5898 entries, 0 to 5897\n",
      "Data columns (total 27 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   bichoice      5898 non-null   int64 \n",
      " 1   range         5898 non-null   int64 \n",
      " 2   home_chg      5898 non-null   int64 \n",
      " 3   work_chg      5898 non-null   int64 \n",
      " 4   town          5898 non-null   int64 \n",
      " 5   highway       5898 non-null   int64 \n",
      " 6   gender        5898 non-null   int64 \n",
      " 7   state         5898 non-null   object\n",
      " 8   Region        5898 non-null   int64 \n",
      " 9   education     5898 non-null   int64 \n",
      " 10  employment    5898 non-null   int64 \n",
      " 11  hsincome      5898 non-null   int64 \n",
      " 12  hsize         5898 non-null   int64 \n",
      " 13  housit        5898 non-null   int64 \n",
      " 14  residence     5898 non-null   int64 \n",
      " 15  all_cars      5898 non-null   int64 \n",
      " 16  ev_cars       5898 non-null   int64 \n",
      " 17  home_parking  5898 non-null   int64 \n",
      " 18  home_evse     5898 non-null   int64 \n",
      " 19  work_parking  5898 non-null   int64 \n",
      " 20  work_evse     5898 non-null   int64 \n",
      " 21  buycar        5898 non-null   int64 \n",
      " 22  zipcode       5898 non-null   int64 \n",
      " 23  dmileage      5898 non-null   int64 \n",
      " 24  long_dist     5898 non-null   int64 \n",
      " 25  Age_category  5898 non-null   int64 \n",
      " 26  RUCA          5898 non-null   int64 \n",
      "dtypes: int64(26), object(1)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bichoice</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>0.550017</td>\n",
       "      <td>0.497534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>range</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.507460</td>\n",
       "      <td>1.112326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_chg</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>5.943371</td>\n",
       "      <td>6.602592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_chg</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>5.899627</td>\n",
       "      <td>6.574685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>town</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.504408</td>\n",
       "      <td>1.124472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.502204</td>\n",
       "      <td>1.115089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>0.503561</td>\n",
       "      <td>0.500030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.899288</td>\n",
       "      <td>1.367156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.703967</td>\n",
       "      <td>0.839617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.659207</td>\n",
       "      <td>1.291301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsincome</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.793489</td>\n",
       "      <td>0.886894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsize</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.672431</td>\n",
       "      <td>1.314606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housit</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.460834</td>\n",
       "      <td>0.620362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residence</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.031536</td>\n",
       "      <td>1.717753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_cars</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.582909</td>\n",
       "      <td>0.719641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ev_cars</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>0.078332</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_parking</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>3.323499</td>\n",
       "      <td>1.865167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_evse</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.835198</td>\n",
       "      <td>0.445773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_parking</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>2.654120</td>\n",
       "      <td>1.400017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_evse</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.962360</td>\n",
       "      <td>0.608242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buycar</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.777213</td>\n",
       "      <td>0.854842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>52330.798576</td>\n",
       "      <td>29095.128072</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>29483.0</td>\n",
       "      <td>48073.0</td>\n",
       "      <td>78258.0</td>\n",
       "      <td>99703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmileage</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>24.750763</td>\n",
       "      <td>20.347513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_dist</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.486267</td>\n",
       "      <td>1.316556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_category</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.949135</td>\n",
       "      <td>0.867394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUCA</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.214649</td>\n",
       "      <td>0.586181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean           std     min      25%      50%  \\\n",
       "bichoice      5898.0      0.550017      0.497534     0.0      0.0      1.0   \n",
       "range         5898.0      2.507460      1.112326     1.0      2.0      3.0   \n",
       "home_chg      5898.0      5.943371      6.602592     0.0      1.0      3.0   \n",
       "work_chg      5898.0      5.899627      6.574685     0.0      1.0      3.0   \n",
       "town          5898.0      2.504408      1.124472     1.0      1.0      3.0   \n",
       "highway       5898.0      2.502204      1.115089     1.0      2.0      2.0   \n",
       "gender        5898.0      0.503561      0.500030     0.0      0.0      1.0   \n",
       "Region        5898.0      2.899288      1.367156     1.0      2.0      3.0   \n",
       "education     5898.0      2.703967      0.839617     1.0      2.0      3.0   \n",
       "employment    5898.0      1.659207      1.291301     1.0      1.0      1.0   \n",
       "hsincome      5898.0      1.793489      0.886894     1.0      1.0      2.0   \n",
       "hsize         5898.0      2.672431      1.314606     1.0      2.0      2.0   \n",
       "housit        5898.0      1.460834      0.620362     1.0      1.0      1.0   \n",
       "residence     5898.0      2.031536      1.717753     1.0      1.0      1.0   \n",
       "all_cars      5898.0      1.582909      0.719641     1.0      1.0      1.0   \n",
       "ev_cars       5898.0      0.078332      0.297468     0.0      0.0      0.0   \n",
       "home_parking  5898.0      3.323499      1.865167     1.0      1.0      3.0   \n",
       "home_evse     5898.0      1.835198      0.445773     1.0      2.0      2.0   \n",
       "work_parking  5898.0      2.654120      1.400017     1.0      2.0      2.0   \n",
       "work_evse     5898.0      1.962360      0.608242     1.0      2.0      2.0   \n",
       "buycar        5898.0      1.777213      0.854842     1.0      1.0      1.0   \n",
       "zipcode       5898.0  52330.798576  29095.128072  1247.0  29483.0  48073.0   \n",
       "dmileage      5898.0     24.750763     20.347513     0.0     10.0     20.0   \n",
       "long_dist     5898.0      1.486267      1.316556     0.0      0.0      1.0   \n",
       "Age_category  5898.0      1.949135      0.867394     1.0      1.0      2.0   \n",
       "RUCA          5898.0      1.214649      0.586181     1.0      1.0      1.0   \n",
       "\n",
       "                  75%      max  \n",
       "bichoice          1.0      1.0  \n",
       "range             3.0      4.0  \n",
       "home_chg         10.0     20.0  \n",
       "work_chg         10.0     20.0  \n",
       "town              4.0      4.0  \n",
       "highway           3.0      4.0  \n",
       "gender            1.0      1.0  \n",
       "Region            4.0      5.0  \n",
       "education         3.0      4.0  \n",
       "employment        2.0      6.0  \n",
       "hsincome          2.0      5.0  \n",
       "hsize             4.0      5.0  \n",
       "housit            2.0      4.0  \n",
       "residence         2.0      8.0  \n",
       "all_cars          2.0      4.0  \n",
       "ev_cars           0.0      4.0  \n",
       "home_parking      5.0      6.0  \n",
       "home_evse         2.0      3.0  \n",
       "work_parking      4.0      6.0  \n",
       "work_evse         2.0      3.0  \n",
       "buycar            3.0      3.0  \n",
       "zipcode       78258.0  99703.0  \n",
       "dmileage         30.0    100.0  \n",
       "long_dist         2.0      4.0  \n",
       "Age_category      2.0      4.0  \n",
       "RUCA              1.0      4.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display column data types in the dataframe\n",
    "print('Datatypes of all the columns in the dataset')\n",
    "print(EV_intention_df.info())\n",
    "EV_intention_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are no null values\n",
    "- All columns are integer type except state which is of object datatype\n",
    "- Some of the attributes need the conversion into their equivalent dummy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Column data types\n",
      "bichoice         int64\n",
      "range            int64\n",
      "home_chg         int64\n",
      "work_chg         int64\n",
      "town             int64\n",
      "highway          int64\n",
      "gender           int64\n",
      "state           object\n",
      "Region           int64\n",
      "education        int64\n",
      "employment       int64\n",
      "hsincome         int64\n",
      "hsize            int64\n",
      "housit           int64\n",
      "residence        int64\n",
      "all_cars         int64\n",
      "ev_cars          int64\n",
      "home_parking     int64\n",
      "home_evse        int64\n",
      "work_parking     int64\n",
      "work_evse        int64\n",
      "buycar           int64\n",
      "zipcode          int64\n",
      "dmileage         int64\n",
      "long_dist        int64\n",
      "Age_category     int64\n",
      "RUCA             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display column data types in the dataframe before modification\n",
    "print('Original Column data types')\n",
    "print(EV_intention_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Category levels and changed variable type:\n",
      "Int64Index([0, 1], dtype='int64')\n",
      "category\n",
      "Index(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
      "       'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
      "       'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
      "       'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
      "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
      "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
      "       'North Carolina', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
      "       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas',\n",
      "       'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
      "       'Wisconsin', 'Wyoming'],\n",
      "      dtype='object')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 8], dtype='int64')\n",
      "category\n",
      "Int64Index([0, 1], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4, 5], dtype='int64')\n",
      "category\n",
      "Int64Index([1, 2, 3, 4], dtype='int64')\n",
      "category\n",
      "Int64Index([0, 1], dtype='int64')\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "# Need to change all the variables with multiple classes to 'category'datatype \n",
    "EV_intention_df.gender = EV_intention_df.gender.astype('category')\n",
    "EV_intention_df.state = EV_intention_df.state.astype('category')\n",
    "EV_intention_df.employment = EV_intention_df.employment.astype('category')\n",
    "EV_intention_df.hsize = EV_intention_df.hsize.astype('category')\n",
    "EV_intention_df.housit = EV_intention_df.housit.astype('category')\n",
    "EV_intention_df.residence = EV_intention_df.residence.astype('category')\n",
    "#EV_intention_df.zipcode = EV_intention_df.zipcode.astype('category')\n",
    "EV_intention_df.buycar = EV_intention_df.buycar.astype('category')\n",
    "EV_intention_df.home_evse = EV_intention_df.home_evse.astype('category')\n",
    "EV_intention_df.work_evse = EV_intention_df.work_evse.astype('category')\n",
    "EV_intention_df.town = EV_intention_df.town.astype('category')\n",
    "EV_intention_df.highway = EV_intention_df.highway.astype('category')\n",
    "EV_intention_df.home_parking = EV_intention_df.home_parking.astype('category')\n",
    "EV_intention_df.work_parking = EV_intention_df.work_parking.astype('category')\n",
    "EV_intention_df.RUCA = EV_intention_df.RUCA.astype('category')\n",
    "EV_intention_df.Region = EV_intention_df.Region.astype('category')\n",
    "EV_intention_df.Age_category = EV_intention_df.Age_category.astype('category')\n",
    "EV_intention_df.education = EV_intention_df.education.astype('category')\n",
    "EV_intention_df.hsincome = EV_intention_df.hsincome.astype('category')\n",
    "EV_intention_df.range = EV_intention_df.range.astype('category')\n",
    "EV_intention_df.bichoice = EV_intention_df.bichoice.astype('category')\n",
    "\n",
    "# Display category levels (attributes) and category type.\n",
    "print(' ')\n",
    "print('Category levels and changed variable type:')\n",
    "print(EV_intention_df.gender.cat.categories)\n",
    "print(EV_intention_df.gender.dtype)\n",
    "print(EV_intention_df.state.cat.categories)\n",
    "print(EV_intention_df.state.dtype)\n",
    "print(EV_intention_df.employment.cat.categories)\n",
    "print(EV_intention_df.employment.dtype)\n",
    "print(EV_intention_df.hsize.cat.categories)\n",
    "print(EV_intention_df.hsize.dtype)\n",
    "print(EV_intention_df.housit.cat.categories)\n",
    "print(EV_intention_df.housit.dtype)\n",
    "print(EV_intention_df.residence.cat.categories)\n",
    "print(EV_intention_df.residence.dtype)\n",
    "print(EV_intention_df.bichoice.cat.categories)\n",
    "print(EV_intention_df.bichoice.dtype)\n",
    "# print(EV_intention_df.zipcode.cat.categories)\n",
    "# print(EV_intention_df.zipcode.dtype)\n",
    "print(EV_intention_df.buycar.cat.categories)\n",
    "print(EV_intention_df.buycar.dtype)\n",
    "print(EV_intention_df.home_evse.cat.categories)\n",
    "print(EV_intention_df.home_evse.dtype)\n",
    "print(EV_intention_df.work_evse.cat.categories)\n",
    "print(EV_intention_df.work_evse.dtype)\n",
    "print(EV_intention_df.town.cat.categories)\n",
    "print(EV_intention_df.town.dtype)\n",
    "print(EV_intention_df.highway.cat.categories)\n",
    "print(EV_intention_df.highway.dtype)\n",
    "print(EV_intention_df.home_parking.cat.categories)\n",
    "print(EV_intention_df.home_parking.dtype)\n",
    "print(EV_intention_df.work_parking.cat.categories)\n",
    "print(EV_intention_df.work_parking.dtype)\n",
    "print(EV_intention_df.RUCA.cat.categories)\n",
    "print(EV_intention_df.RUCA.dtype)\n",
    "print(EV_intention_df.Region.cat.categories)\n",
    "print(EV_intention_df.Region.dtype)\n",
    "print(EV_intention_df.Age_category.cat.categories)\n",
    "print(EV_intention_df.Age_category.dtype)\n",
    "print(EV_intention_df.education.cat.categories)\n",
    "print(EV_intention_df.education.dtype)\n",
    "print(EV_intention_df.hsincome.cat.categories)\n",
    "print(EV_intention_df.hsincome.dtype)\n",
    "print(EV_intention_df.range.cat.categories)\n",
    "print(EV_intention_df.range.dtype)\n",
    "print(EV_intention_df.bichoice.cat.categories)\n",
    "print(EV_intention_df.bichoice.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state bichoice range  home_chg  work_chg town highway gender Region  \\\n",
      "0      20.0        0     1         3         1    3       2      0      1   \n",
      "1      20.0        0     4         3         3    4       2      0      1   \n",
      "2      20.0        0     2         5         0    2       4      0      1   \n",
      "3      20.0        0     4         5         0    1       1      0      1   \n",
      "4      20.0        0     1         5         0    1       2      0      1   \n",
      "...     ...      ...   ...       ...       ...  ...     ...    ...    ...   \n",
      "5893    1.0        0     2        10         5    2       2      0      5   \n",
      "5894    1.0        1     3         1         3    4       3      0      5   \n",
      "5895    1.0        0     1        20         2    2       4      0      5   \n",
      "5896    1.0        0     2        20         5    4       2      0      5   \n",
      "5897    1.0        0     1         2         1    3       1      0      5   \n",
      "\n",
      "     education  ... home_parking home_evse work_parking work_evse buycar  \\\n",
      "0            4  ...            3         2            5         2      3   \n",
      "1            4  ...            3         2            5         2      3   \n",
      "2            4  ...            3         2            5         2      3   \n",
      "3            4  ...            3         2            5         2      3   \n",
      "4            4  ...            3         2            5         2      3   \n",
      "...        ...  ...          ...       ...          ...       ...    ...   \n",
      "5893         2  ...            6         1            4         2      3   \n",
      "5894         2  ...            6         1            4         2      3   \n",
      "5895         2  ...            6         1            4         2      3   \n",
      "5896         2  ...            6         1            4         2      3   \n",
      "5897         2  ...            6         1            4         2      3   \n",
      "\n",
      "      zipcode  dmileage long_dist Age_category RUCA  \n",
      "0        1247        20         2            3    2  \n",
      "1        1247        20         2            3    2  \n",
      "2        1247        20         2            3    2  \n",
      "3        1247        20         2            3    2  \n",
      "4        1247        20         2            3    2  \n",
      "...       ...       ...       ...          ...  ...  \n",
      "5893    99703        25         3            2    1  \n",
      "5894    99703        25         3            2    1  \n",
      "5895    99703        25         3            2    1  \n",
      "5896    99703        25         3            2    1  \n",
      "5897    99703        25         3            2    1  \n",
      "\n",
      "[5898 rows x 27 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5898, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoded_columns= ['state']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories='auto')\n",
    "ordinal_encoded_data = ordinal_encoder.fit_transform(EV_intention_df[ordinal_encoded_columns])\n",
    "\n",
    "#Convert it to df\n",
    "ordinal_encoded_data_df = pd.DataFrame(ordinal_encoded_data, index=EV_intention_df.index,columns=['state'])\n",
    "# # ordinal_encoded_data_df.columns = ordinal_encoder.get_feature_names_out(input_features=EV_intention_df[ordinal_encoded_columns])\n",
    "\n",
    "# #Extract only the columns that didnt need to be encoded\n",
    "data_other_cols = EV_intention_df.drop(columns=ordinal_encoded_columns)\n",
    "\n",
    "# #Concatenate the two dataframes : \n",
    "EV_intention_df = pd.concat([ordinal_encoded_data_df, data_other_cols], axis=1)\n",
    "print(EV_intention_df)\n",
    "EV_intention_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_intention_df.state = EV_intention_df.state.astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Column data types\n",
      "state           category\n",
      "bichoice        category\n",
      "range           category\n",
      "home_chg           int64\n",
      "work_chg           int64\n",
      "town            category\n",
      "highway         category\n",
      "gender          category\n",
      "Region          category\n",
      "education       category\n",
      "employment      category\n",
      "hsincome        category\n",
      "hsize           category\n",
      "housit          category\n",
      "residence       category\n",
      "all_cars           int64\n",
      "ev_cars            int64\n",
      "home_parking    category\n",
      "home_evse       category\n",
      "work_parking    category\n",
      "work_evse       category\n",
      "buycar          category\n",
      "zipcode            int64\n",
      "dmileage           int64\n",
      "long_dist          int64\n",
      "Age_category    category\n",
      "RUCA            category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display column data types in the dataframe after modification\n",
    "print('Modified Column data types')\n",
    "print(EV_intention_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>home_chg</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_chg</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_cars</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ev_cars</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>52330.80</td>\n",
       "      <td>29095.13</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>29483.0</td>\n",
       "      <td>48073.0</td>\n",
       "      <td>78258.0</td>\n",
       "      <td>99703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmileage</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>20.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_dist</th>\n",
       "      <td>5898.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count      mean       std     min      25%      50%      75%  \\\n",
       "home_chg   5898.0      5.94      6.60     0.0      1.0      3.0     10.0   \n",
       "work_chg   5898.0      5.90      6.57     0.0      1.0      3.0     10.0   \n",
       "all_cars   5898.0      1.58      0.72     1.0      1.0      1.0      2.0   \n",
       "ev_cars    5898.0      0.08      0.30     0.0      0.0      0.0      0.0   \n",
       "zipcode    5898.0  52330.80  29095.13  1247.0  29483.0  48073.0  78258.0   \n",
       "dmileage   5898.0     24.75     20.35     0.0     10.0     20.0     30.0   \n",
       "long_dist  5898.0      1.49      1.32     0.0      0.0      1.0      2.0   \n",
       "\n",
       "               max  \n",
       "home_chg      20.0  \n",
       "work_chg      20.0  \n",
       "all_cars       4.0  \n",
       "ev_cars        4.0  \n",
       "zipcode    99703.0  \n",
       "dmileage     100.0  \n",
       "long_dist      4.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use describe() function to display column statistics for the entire data set. \n",
    "np.round(EV_intention_df.describe(), decimals=2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :  (4128, 25)\n",
      "Validation :  (1770, 25)\n"
     ]
    }
   ],
   "source": [
    "#Develop predictors X and output variable Y for the data set.\n",
    "X = EV_intention_df.drop(columns=['bichoice','zipcode'])\n",
    "y = EV_intention_df['bichoice']\n",
    "\n",
    "# Develop training (60%) and validation(40% or 0.4) partitions for\n",
    "# heart_disease_df data frame.\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print('Training : ', train_X.shape)\n",
    "print('Validation : ', valid_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity analysis of k in k-fold cross-validation\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors list\n",
      "Index(['state', 'range', 'home_chg', 'work_chg', 'town', 'highway', 'gender',\n",
      "       'Region', 'education', 'employment', 'hsincome', 'hsize', 'housit',\n",
      "       'residence', 'all_cars', 'ev_cars', 'home_parking', 'home_evse',\n",
      "       'work_parking', 'work_evse', 'buycar', 'dmileage', 'long_dist',\n",
      "       'Age_category', 'RUCA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Predictors list')\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the use of an array of column names.\n",
    "scaler.fit(X[['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA']])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized (Normalized) Values of EV Intention Data Set\n",
      "\n",
      "        zstate    zrange  zhome_chg  zwork_chg     ztown  zhighway   zgender  \\\n",
      "5495  0.783612  1.341933  -0.142891  -0.136844  0.440770  1.343321 -1.007147   \n",
      "2146 -1.078659  1.341933   0.614452  -0.593178 -1.337993  1.343321  0.992904   \n",
      "1893 -1.078659  1.341933  -0.597297   2.144828 -0.448612 -1.347275  0.992904   \n",
      "4741 -1.492498  0.442839   0.614452  -0.441066 -1.337993 -0.450409 -1.007147   \n",
      "1686 -1.078659 -0.456254   0.614452  -0.136844 -0.448612 -0.450409  0.992904   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "905   1.404369 -1.355348  -0.597297   2.144828 -0.448612  1.343321 -1.007147   \n",
      "5192 -1.354552  0.442839   0.614452  -0.136844  1.330152  1.343321  0.992904   \n",
      "3980 -0.457902 -1.355348  -0.142891  -0.136844 -1.337993  0.446456 -1.007147   \n",
      "235   1.335396 -0.456254   2.129137  -0.136844  1.330152 -0.450409  0.992904   \n",
      "5157 -1.354552  0.442839  -0.445828  -0.897401 -0.448612 -1.347275  0.992904   \n",
      "\n",
      "       zRegion  zeducation  zemployment  ...  ev_cars  home_parking  \\\n",
      "5495  1.536686   -0.838510     0.263937  ...        0             3   \n",
      "2146 -0.657836   -0.838510    -0.510541  ...        0             6   \n",
      "1893 -0.657836    0.352610    -0.510541  ...        0             6   \n",
      "4741  0.805179    0.352610     2.587372  ...        0             1   \n",
      "1686 -0.657836    0.352610    -0.510541  ...        0             3   \n",
      "...        ...         ...          ...  ...      ...           ...   \n",
      "905  -0.657836   -0.838510    -0.510541  ...        0             1   \n",
      "5192  1.536686   -2.029631    -0.510541  ...        0             6   \n",
      "3980 -0.657836   -2.029631     0.263937  ...        0             3   \n",
      "235  -1.389343    0.352610    -0.510541  ...        0             1   \n",
      "5157  1.536686   -0.838510     0.263937  ...        0             6   \n",
      "\n",
      "      home_evse  work_parking  work_evse  buycar  dmileage  long_dist  \\\n",
      "5495          1             5          1       1        10          1   \n",
      "2146          2             2          2       2        15          0   \n",
      "1893          2             2          2       1       100          4   \n",
      "4741          2             2          3       3         5          0   \n",
      "1686          1             2          1       3        30          2   \n",
      "...         ...           ...        ...     ...       ...        ...   \n",
      "905           2             2          2       1        15          0   \n",
      "5192          2             2          2       2        60          0   \n",
      "3980          1             2          2       1        45          1   \n",
      "235           2             2          2       1        25          0   \n",
      "5157          2             2          3       3        30          2   \n",
      "\n",
      "      Age_category  RUCA  \n",
      "5495             3     1  \n",
      "2146             2     1  \n",
      "1893             2     1  \n",
      "4741             4     1  \n",
      "1686             1     1  \n",
      "...            ...   ...  \n",
      "905              1     1  \n",
      "5192             1     1  \n",
      "3980             2     1  \n",
      "235              4     4  \n",
      "5157             3     1  \n",
      "\n",
      "[4128 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform the full data set into standardized (normalized) data set. \n",
    "#train_X.reset_index(drop=True,inplace=True)\n",
    "train_X = pd.concat([pd.DataFrame(scaler.transform(train_X[['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA']]), \n",
    "                                    columns=['zstate','zrange', 'zhome_chg', 'zwork_chg', 'ztown', 'zhighway', 'zgender', 'zRegion',\n",
    "       'zeducation', 'zemployment', 'zhsincome', 'zhsize', 'zhousit', 'zresidence',\n",
    "       'zall_cars', 'zev_cars', 'zhome_parking', 'zhome_evse', 'zwork_parking',\n",
    "       'zwork_evse', 'zbuycar', 'zdmileage', 'zlong_dist', 'zAge_category', 'zRUCA'],index=train_X.index),\n",
    "                       train_X ], axis=1)\n",
    "print('Standardized (Normalized) Values of EV Intention Data Set')\n",
    "print()\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized (Normalized) Values of EV Intention Data Set\n",
      "\n",
      "        zstate    zrange  zhome_chg  zwork_chg     ztown  zhighway   zgender  \\\n",
      "573   0.852585 -0.456254  -0.900234  -0.441066 -0.448612 -1.347275 -1.007147   \n",
      "3219  1.611288  0.442839   2.129137  -0.745289 -0.448612  0.446456 -1.007147   \n",
      "4436  1.197450 -1.355348   2.129137  -0.593178  0.440770 -0.450409  0.992904   \n",
      "3887  0.162855  0.442839   0.614452   2.144828 -0.448612 -0.450409 -1.007147   \n",
      "3656  0.024909  1.341933  -0.142891   0.623714  0.440770 -0.450409 -1.007147   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "3321 -0.113037 -0.456254  -0.597297  -0.136844  1.330152 -1.347275 -1.007147   \n",
      "2105 -1.078659 -0.456254  -0.445828  -0.745289 -0.448612  1.343321  0.992904   \n",
      "710   0.852585  1.341933  -0.597297   2.144828 -0.448612 -1.347275 -1.007147   \n",
      "4302  1.197450  1.341933  -0.597297  -0.136844  0.440770 -1.347275  0.992904   \n",
      "3201  1.611288  0.442839  -0.597297   0.623714 -0.448612 -0.450409 -1.007147   \n",
      "\n",
      "       zRegion  zeducation  zemployment  ...  ev_cars  home_parking  \\\n",
      "573  -1.389343    0.352610    -0.510541  ...        0             1   \n",
      "3219  0.073672    1.543731     0.263937  ...        0             6   \n",
      "4436  0.805179   -0.838510    -0.510541  ...        0             3   \n",
      "3887  0.073672    0.352610     0.263937  ...        0             6   \n",
      "3656  0.073672    0.352610     1.038415  ...        0             4   \n",
      "...        ...         ...          ...  ...      ...           ...   \n",
      "3321  0.073672   -0.838510     1.038415  ...        0             6   \n",
      "2105 -0.657836   -0.838510    -0.510541  ...        0             1   \n",
      "710  -1.389343    0.352610    -0.510541  ...        0             4   \n",
      "4302  0.805179    0.352610    -0.510541  ...        0             2   \n",
      "3201  0.073672    0.352610    -0.510541  ...        0             6   \n",
      "\n",
      "      home_evse  work_parking  work_evse  buycar  dmileage  long_dist  \\\n",
      "573           1             6          1       1        15          1   \n",
      "3219          2             2          2       1        20          0   \n",
      "4436          2             2          2       2         5          2   \n",
      "3887          2             3          2       2        15          1   \n",
      "3656          2             3          2       1        30          0   \n",
      "...         ...           ...        ...     ...       ...        ...   \n",
      "3321          2             5          1       3        10          0   \n",
      "2105          2             5          2       1        20          0   \n",
      "710           2             2          2       1        15          2   \n",
      "4302          1             2          2       1        60          2   \n",
      "3201          2             2          2       3        20          2   \n",
      "\n",
      "      Age_category  RUCA  \n",
      "573              2     1  \n",
      "3219             2     1  \n",
      "4436             1     2  \n",
      "3887             1     1  \n",
      "3656             1     1  \n",
      "...            ...   ...  \n",
      "3321             1     1  \n",
      "2105             2     1  \n",
      "710              1     1  \n",
      "4302             1     1  \n",
      "3201             3     1  \n",
      "\n",
      "[1770 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform the full data set into standardized (normalized) data set. \n",
    "#valid_X.reset_index(drop=True,inplace=True)\n",
    "valid_X = pd.concat([pd.DataFrame(scaler.transform(valid_X[['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA']]), \n",
    "                                    columns=['zstate','zrange', 'zhome_chg', 'zwork_chg', 'ztown', 'zhighway', 'zgender', 'zRegion',\n",
    "       'zeducation', 'zemployment', 'zhsincome', 'zhsize', 'zhousit', 'zresidence',\n",
    "       'zall_cars', 'zev_cars', 'zhome_parking', 'zhome_evse', 'zwork_parking',\n",
    "       'zwork_evse', 'zbuycar', 'zdmileage', 'zlong_dist', 'zAge_category', 'zRUCA'],index=valid_X.index),\n",
    "                       valid_X ], axis=1)\n",
    "print('Standardized (Normalized) Values of EV Intention Data Set')\n",
    "print()\n",
    "print(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        zstate    zrange  zhome_chg  zwork_chg     ztown  zhighway   zgender  \\\n",
      "5495  0.783612  1.341933  -0.142891  -0.136844  0.440770  1.343321 -1.007147   \n",
      "2146 -1.078659  1.341933   0.614452  -0.593178 -1.337993  1.343321  0.992904   \n",
      "1893 -1.078659  1.341933  -0.597297   2.144828 -0.448612 -1.347275  0.992904   \n",
      "4741 -1.492498  0.442839   0.614452  -0.441066 -1.337993 -0.450409 -1.007147   \n",
      "1686 -1.078659 -0.456254   0.614452  -0.136844 -0.448612 -0.450409  0.992904   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "905   1.404369 -1.355348  -0.597297   2.144828 -0.448612  1.343321 -1.007147   \n",
      "5192 -1.354552  0.442839   0.614452  -0.136844  1.330152  1.343321  0.992904   \n",
      "3980 -0.457902 -1.355348  -0.142891  -0.136844 -1.337993  0.446456 -1.007147   \n",
      "235   1.335396 -0.456254   2.129137  -0.136844  1.330152 -0.450409  0.992904   \n",
      "5157 -1.354552  0.442839  -0.445828  -0.897401 -0.448612 -1.347275  0.992904   \n",
      "\n",
      "       zRegion  zeducation  zemployment  ...  zev_cars  zhome_parking  \\\n",
      "5495  1.536686   -0.838510     0.263937  ...  -0.26335      -0.173457   \n",
      "2146 -0.657836   -0.838510    -0.510541  ...  -0.26335       1.435114   \n",
      "1893 -0.657836    0.352610    -0.510541  ...  -0.26335       1.435114   \n",
      "4741  0.805179    0.352610     2.587372  ...  -0.26335      -1.245838   \n",
      "1686 -0.657836    0.352610    -0.510541  ...  -0.26335      -0.173457   \n",
      "...        ...         ...          ...  ...       ...            ...   \n",
      "905  -0.657836   -0.838510    -0.510541  ...  -0.26335      -1.245838   \n",
      "5192  1.536686   -2.029631    -0.510541  ...  -0.26335       1.435114   \n",
      "3980 -0.657836   -2.029631     0.263937  ...  -0.26335      -0.173457   \n",
      "235  -1.389343    0.352610    -0.510541  ...  -0.26335      -1.245838   \n",
      "5157  1.536686   -0.838510     0.263937  ...  -0.26335       1.435114   \n",
      "\n",
      "      zhome_evse  zwork_parking  zwork_evse   zbuycar  zdmileage  zlong_dist  \\\n",
      "5495   -1.873755       1.675750   -1.582334 -0.909266  -0.725003   -0.369379   \n",
      "2146    0.369730      -0.467262    0.061888  0.260640  -0.479252   -1.129001   \n",
      "1893    0.369730      -0.467262    0.061888 -0.909266   3.698517    1.909487   \n",
      "4741    0.369730      -0.467262    1.706110  1.430547  -0.970754   -1.129001   \n",
      "1686   -1.873755      -0.467262   -1.582334  1.430547   0.258001    0.390243   \n",
      "...          ...            ...         ...       ...        ...         ...   \n",
      "905     0.369730      -0.467262    0.061888 -0.909266  -0.479252   -1.129001   \n",
      "5192    0.369730      -0.467262    0.061888  0.260640   1.732508   -1.129001   \n",
      "3980   -1.873755      -0.467262    0.061888 -0.909266   0.995254   -0.369379   \n",
      "235     0.369730      -0.467262    0.061888 -0.909266   0.012250   -1.129001   \n",
      "5157    0.369730      -0.467262    1.706110  1.430547   0.258001    0.390243   \n",
      "\n",
      "      zAge_category     zRUCA  \n",
      "5495       1.211622 -0.366213  \n",
      "2146       0.058646 -0.366213  \n",
      "1893       0.058646 -0.366213  \n",
      "4741       2.364598 -0.366213  \n",
      "1686      -1.094330 -0.366213  \n",
      "...             ...       ...  \n",
      "905       -1.094330 -0.366213  \n",
      "5192      -1.094330 -0.366213  \n",
      "3980       0.058646 -0.366213  \n",
      "235        2.364598  4.752097  \n",
      "5157       1.211622 -0.366213  \n",
      "\n",
      "[4128 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "train_X_s = train_X.drop(columns= ['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA'])\n",
    "print(train_X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        zstate    zrange  zhome_chg  zwork_chg     ztown  zhighway   zgender  \\\n",
      "573   0.852585 -0.456254  -0.900234  -0.441066 -0.448612 -1.347275 -1.007147   \n",
      "3219  1.611288  0.442839   2.129137  -0.745289 -0.448612  0.446456 -1.007147   \n",
      "4436  1.197450 -1.355348   2.129137  -0.593178  0.440770 -0.450409  0.992904   \n",
      "3887  0.162855  0.442839   0.614452   2.144828 -0.448612 -0.450409 -1.007147   \n",
      "3656  0.024909  1.341933  -0.142891   0.623714  0.440770 -0.450409 -1.007147   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "3321 -0.113037 -0.456254  -0.597297  -0.136844  1.330152 -1.347275 -1.007147   \n",
      "2105 -1.078659 -0.456254  -0.445828  -0.745289 -0.448612  1.343321  0.992904   \n",
      "710   0.852585  1.341933  -0.597297   2.144828 -0.448612 -1.347275 -1.007147   \n",
      "4302  1.197450  1.341933  -0.597297  -0.136844  0.440770 -1.347275  0.992904   \n",
      "3201  1.611288  0.442839  -0.597297   0.623714 -0.448612 -0.450409 -1.007147   \n",
      "\n",
      "       zRegion  zeducation  zemployment  ...  zev_cars  zhome_parking  \\\n",
      "573  -1.389343    0.352610    -0.510541  ...  -0.26335      -1.245838   \n",
      "3219  0.073672    1.543731     0.263937  ...  -0.26335       1.435114   \n",
      "4436  0.805179   -0.838510    -0.510541  ...  -0.26335      -0.173457   \n",
      "3887  0.073672    0.352610     0.263937  ...  -0.26335       1.435114   \n",
      "3656  0.073672    0.352610     1.038415  ...  -0.26335       0.362733   \n",
      "...        ...         ...          ...  ...       ...            ...   \n",
      "3321  0.073672   -0.838510     1.038415  ...  -0.26335       1.435114   \n",
      "2105 -0.657836   -0.838510    -0.510541  ...  -0.26335      -1.245838   \n",
      "710  -1.389343    0.352610    -0.510541  ...  -0.26335       0.362733   \n",
      "4302  0.805179    0.352610    -0.510541  ...  -0.26335      -0.709648   \n",
      "3201  0.073672    0.352610    -0.510541  ...  -0.26335       1.435114   \n",
      "\n",
      "      zhome_evse  zwork_parking  zwork_evse   zbuycar  zdmileage  zlong_dist  \\\n",
      "573    -1.873755       2.390087   -1.582334 -0.909266  -0.479252   -0.369379   \n",
      "3219    0.369730      -0.467262    0.061888 -0.909266  -0.233501   -1.129001   \n",
      "4436    0.369730      -0.467262    0.061888  0.260640  -0.970754    0.390243   \n",
      "3887    0.369730       0.247075    0.061888  0.260640  -0.479252   -0.369379   \n",
      "3656    0.369730       0.247075    0.061888 -0.909266   0.258001   -1.129001   \n",
      "...          ...            ...         ...       ...        ...         ...   \n",
      "3321    0.369730       1.675750   -1.582334  1.430547  -0.725003   -1.129001   \n",
      "2105    0.369730       1.675750    0.061888 -0.909266  -0.233501   -1.129001   \n",
      "710     0.369730      -0.467262    0.061888 -0.909266  -0.479252    0.390243   \n",
      "4302   -1.873755      -0.467262    0.061888 -0.909266   1.732508    0.390243   \n",
      "3201    0.369730      -0.467262    0.061888  1.430547  -0.233501    0.390243   \n",
      "\n",
      "      zAge_category     zRUCA  \n",
      "573        0.058646 -0.366213  \n",
      "3219       0.058646 -0.366213  \n",
      "4436      -1.094330  1.339890  \n",
      "3887      -1.094330 -0.366213  \n",
      "3656      -1.094330 -0.366213  \n",
      "...             ...       ...  \n",
      "3321      -1.094330 -0.366213  \n",
      "2105       0.058646 -0.366213  \n",
      "710       -1.094330 -0.366213  \n",
      "4302      -1.094330 -0.366213  \n",
      "3201       1.211622 -0.366213  \n",
      "\n",
      "[1770 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "valid_X_s = valid_X.drop(columns= ['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA'])\n",
    "print(valid_X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized (Normalized) Values of EV Intention Data Set\n",
      "\n",
      "        zstate    zrange  zhome_chg  zwork_chg     ztown  zhighway   zgender  \\\n",
      "0    -0.250983 -1.355348  -0.445828  -0.745289  0.440770 -0.450409 -1.007147   \n",
      "1    -0.250983  1.341933  -0.445828  -0.441066  1.330152 -0.450409 -1.007147   \n",
      "2    -0.250983 -0.456254  -0.142891  -0.897401 -0.448612  1.343321 -1.007147   \n",
      "3    -0.250983  1.341933  -0.142891  -0.897401 -1.337993 -1.347275 -1.007147   \n",
      "4    -0.250983 -1.355348  -0.142891  -0.897401 -1.337993 -0.450409 -1.007147   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "5893 -1.561471 -0.456254   0.614452  -0.136844 -0.448612 -0.450409 -1.007147   \n",
      "5894 -1.561471  0.442839  -0.748765  -0.441066  1.330152  0.446456 -1.007147   \n",
      "5895 -1.561471 -1.355348   2.129137  -0.593178 -0.448612  1.343321 -1.007147   \n",
      "5896 -1.561471 -0.456254   2.129137  -0.136844  1.330152 -0.450409 -1.007147   \n",
      "5897 -1.561471 -1.355348  -0.597297  -0.745289  0.440770 -1.347275 -1.007147   \n",
      "\n",
      "       zRegion  zeducation  zemployment  ...  ev_cars  home_parking  \\\n",
      "0    -1.389343    1.543731     1.812894  ...        0             3   \n",
      "1    -1.389343    1.543731     1.812894  ...        0             3   \n",
      "2    -1.389343    1.543731     1.812894  ...        0             3   \n",
      "3    -1.389343    1.543731     1.812894  ...        0             3   \n",
      "4    -1.389343    1.543731     1.812894  ...        0             3   \n",
      "...        ...         ...          ...  ...      ...           ...   \n",
      "5893  1.536686   -0.838510    -0.510541  ...        0             6   \n",
      "5894  1.536686   -0.838510    -0.510541  ...        0             6   \n",
      "5895  1.536686   -0.838510    -0.510541  ...        0             6   \n",
      "5896  1.536686   -0.838510    -0.510541  ...        0             6   \n",
      "5897  1.536686   -0.838510    -0.510541  ...        0             6   \n",
      "\n",
      "      home_evse  work_parking  work_evse  buycar  dmileage  long_dist  \\\n",
      "0             2             5          2       3        20          2   \n",
      "1             2             5          2       3        20          2   \n",
      "2             2             5          2       3        20          2   \n",
      "3             2             5          2       3        20          2   \n",
      "4             2             5          2       3        20          2   \n",
      "...         ...           ...        ...     ...       ...        ...   \n",
      "5893          1             4          2       3        25          3   \n",
      "5894          1             4          2       3        25          3   \n",
      "5895          1             4          2       3        25          3   \n",
      "5896          1             4          2       3        25          3   \n",
      "5897          1             4          2       3        25          3   \n",
      "\n",
      "      Age_category  RUCA  \n",
      "0                3     2  \n",
      "1                3     2  \n",
      "2                3     2  \n",
      "3                3     2  \n",
      "4                3     2  \n",
      "...            ...   ...  \n",
      "5893             2     1  \n",
      "5894             2     1  \n",
      "5895             2     1  \n",
      "5896             2     1  \n",
      "5897             2     1  \n",
      "\n",
      "[5898 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform the full data set into standardized (normalized) data set. \n",
    "#train_X.reset_index(drop=True,inplace=True)\n",
    "full_X = pd.concat([pd.DataFrame(scaler.transform(X[['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA']]), \n",
    "                                    columns=['zstate','zrange', 'zhome_chg', 'zwork_chg', 'ztown', 'zhighway', 'zgender', 'zRegion',\n",
    "       'zeducation', 'zemployment', 'zhsincome', 'zhsize', 'zhousit', 'zresidence',\n",
    "       'zall_cars', 'zev_cars', 'zhome_parking', 'zhome_evse', 'zwork_parking',\n",
    "       'zwork_evse', 'zbuycar', 'zdmileage', 'zlong_dist', 'zAge_category', 'zRUCA'],index=X.index),\n",
    "                       X ], axis=1)\n",
    "print('Standardized (Normalized) Values of EV Intention Data Set')\n",
    "print()\n",
    "print(full_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        zstate    zrange  zhome_chg  zwork_chg     ztown  zhighway   zgender  \\\n",
      "0    -0.250983 -1.355348  -0.445828  -0.745289  0.440770 -0.450409 -1.007147   \n",
      "1    -0.250983  1.341933  -0.445828  -0.441066  1.330152 -0.450409 -1.007147   \n",
      "2    -0.250983 -0.456254  -0.142891  -0.897401 -0.448612  1.343321 -1.007147   \n",
      "3    -0.250983  1.341933  -0.142891  -0.897401 -1.337993 -1.347275 -1.007147   \n",
      "4    -0.250983 -1.355348  -0.142891  -0.897401 -1.337993 -0.450409 -1.007147   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "5893 -1.561471 -0.456254   0.614452  -0.136844 -0.448612 -0.450409 -1.007147   \n",
      "5894 -1.561471  0.442839  -0.748765  -0.441066  1.330152  0.446456 -1.007147   \n",
      "5895 -1.561471 -1.355348   2.129137  -0.593178 -0.448612  1.343321 -1.007147   \n",
      "5896 -1.561471 -0.456254   2.129137  -0.136844  1.330152 -0.450409 -1.007147   \n",
      "5897 -1.561471 -1.355348  -0.597297  -0.745289  0.440770 -1.347275 -1.007147   \n",
      "\n",
      "       zRegion  zeducation  zemployment  ...  zev_cars  zhome_parking  \\\n",
      "0    -1.389343    1.543731     1.812894  ...  -0.26335      -0.173457   \n",
      "1    -1.389343    1.543731     1.812894  ...  -0.26335      -0.173457   \n",
      "2    -1.389343    1.543731     1.812894  ...  -0.26335      -0.173457   \n",
      "3    -1.389343    1.543731     1.812894  ...  -0.26335      -0.173457   \n",
      "4    -1.389343    1.543731     1.812894  ...  -0.26335      -0.173457   \n",
      "...        ...         ...          ...  ...       ...            ...   \n",
      "5893  1.536686   -0.838510    -0.510541  ...  -0.26335       1.435114   \n",
      "5894  1.536686   -0.838510    -0.510541  ...  -0.26335       1.435114   \n",
      "5895  1.536686   -0.838510    -0.510541  ...  -0.26335       1.435114   \n",
      "5896  1.536686   -0.838510    -0.510541  ...  -0.26335       1.435114   \n",
      "5897  1.536686   -0.838510    -0.510541  ...  -0.26335       1.435114   \n",
      "\n",
      "      zhome_evse  zwork_parking  zwork_evse   zbuycar  zdmileage  zlong_dist  \\\n",
      "0       0.369730       1.675750    0.061888  1.430547  -0.233501    0.390243   \n",
      "1       0.369730       1.675750    0.061888  1.430547  -0.233501    0.390243   \n",
      "2       0.369730       1.675750    0.061888  1.430547  -0.233501    0.390243   \n",
      "3       0.369730       1.675750    0.061888  1.430547  -0.233501    0.390243   \n",
      "4       0.369730       1.675750    0.061888  1.430547  -0.233501    0.390243   \n",
      "...          ...            ...         ...       ...        ...         ...   \n",
      "5893   -1.873755       0.961412    0.061888  1.430547   0.012250    1.149865   \n",
      "5894   -1.873755       0.961412    0.061888  1.430547   0.012250    1.149865   \n",
      "5895   -1.873755       0.961412    0.061888  1.430547   0.012250    1.149865   \n",
      "5896   -1.873755       0.961412    0.061888  1.430547   0.012250    1.149865   \n",
      "5897   -1.873755       0.961412    0.061888  1.430547   0.012250    1.149865   \n",
      "\n",
      "      zAge_category     zRUCA  \n",
      "0          1.211622  1.339890  \n",
      "1          1.211622  1.339890  \n",
      "2          1.211622  1.339890  \n",
      "3          1.211622  1.339890  \n",
      "4          1.211622  1.339890  \n",
      "...             ...       ...  \n",
      "5893       0.058646 -0.366213  \n",
      "5894       0.058646 -0.366213  \n",
      "5895       0.058646 -0.366213  \n",
      "5896       0.058646 -0.366213  \n",
      "5897       0.058646 -0.366213  \n",
      "\n",
      "[5898 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "full_X_s = full_X.drop(columns= ['state','range', 'home_chg', 'work_chg', 'town', 'highway', 'gender', 'Region',\n",
    "       'education', 'employment', 'hsincome', 'hsize', 'housit', 'residence',\n",
    "       'all_cars', 'ev_cars', 'home_parking', 'home_evse', 'work_parking',\n",
    "       'work_evse', 'buycar', 'dmileage', 'long_dist', 'Age_category', 'RUCA'])\n",
    "print(full_X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(train_X_s)\n",
    "# y = EV_intention_df['bichoice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier()\n",
    "model2 = GradientBoostingClassifier()\n",
    "model3 = XGBClassifier(n_estimators=500,\n",
    "                      max_depth=6,\n",
    "                      #eval_metric=mean_squared_error,\n",
    "                      learning_rate = 0.05,\n",
    "                      reg_alpha = 1,\n",
    "                      reg_lambda = 5)\n",
    "#model4 = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=5)\n",
    "model5 = LGBMClassifier()\n",
    "model6 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StackingRegressor with the base models as estimators\n",
    "reg = StackingClassifier(\n",
    "    estimators=[('rf', model1), ('gb', model2), ('xgb', model3),('lgbm', model5)],\n",
    "    final_estimator=model6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:44:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:44:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:44:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:44:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:44:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:44:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier()),\n",
       "                               ('gb', GradientBoostingClassifier()),\n",
       "                               ('xgb',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.05,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=500, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=1, reg_lambda=5,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None)),\n",
       "                               ('lgbm', LGBMClassifier())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(train_X_s, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = reg.score(X_test, y_test)\n",
    "# print(f\"R^2 score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacking classifier training Accuracy: 1.00\n",
      "Stacking classifier test Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nStacking classifier training Accuracy: {reg.score(train_X_s, train_y):0.2f}\")\n",
    "print(f\"Stacking classifier test Accuracy: {reg.score(valid_X_s, valid_y):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = reg.predict(train_X_s)\n",
    "pred_test =reg.predict(valid_X_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Partition\n",
      "Confusion Matrix (Accuracy 0.9988)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1833    4\n",
      "     1    1 2290\n",
      "\n",
      "Validation Partition\n",
      "Confusion Matrix (Accuracy 0.7435)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 545 272\n",
      "     1 182 771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       817\n",
      "           1       0.74      0.81      0.77       953\n",
      "\n",
      "    accuracy                           0.74      1770\n",
      "   macro avg       0.74      0.74      0.74      1770\n",
      "weighted avg       0.74      0.74      0.74      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrices for multiple predictors logistic model. \n",
    "\n",
    "# Identify and display confusion matrix for training partition. \n",
    "print('Training Partition')\n",
    "classificationSummary(train_y, reg.predict(train_X_s))\n",
    "\n",
    "# Identify and display confusion matrix for validation partition. \n",
    "print()\n",
    "print('Validation Partition')\n",
    "classificationSummary(valid_y, reg.predict(valid_X_s))\n",
    "print(classification_report(valid_y, reg.predict(valid_X_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFOLD CV- 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754 (0.008)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a random forest model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model1, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.669 (0.012)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a Gradient boosting model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model2, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748 (0.013)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a XGBClassifier model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model3, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.739 (0.014)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a LGBM model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model5, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.617 (0.020)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a Logistic regression model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model6, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.763 (0.030)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a random forest model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=30, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model1, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.672 (0.040)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a gradient boosting model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=30, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model2, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.753 (0.032)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a XGB Classifier model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=30, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model3, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.742 (0.032)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a LGBM model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=30, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model5, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.616 (0.038)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:37:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a logistic regression model using k-fold cross-validation\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=30, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model6, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold CV (only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal: 0.626\n",
      "> folds=2, accuracy=0.599 (0.594,0.604)\n",
      "> folds=3, accuracy=0.588 (0.561,0.605)\n",
      "> folds=4, accuracy=0.610 (0.592,0.628)\n",
      "> folds=5, accuracy=0.601 (0.572,0.622)\n",
      "> folds=6, accuracy=0.615 (0.607,0.623)\n",
      "> folds=7, accuracy=0.612 (0.588,0.637)\n",
      "> folds=8, accuracy=0.620 (0.585,0.636)\n",
      "> folds=9, accuracy=0.620 (0.586,0.672)\n",
      "> folds=10, accuracy=0.609 (0.568,0.642)\n",
      "> folds=11, accuracy=0.619 (0.590,0.660)\n",
      "> folds=12, accuracy=0.624 (0.597,0.648)\n",
      "> folds=13, accuracy=0.626 (0.579,0.663)\n",
      "> folds=14, accuracy=0.615 (0.582,0.694)\n",
      "> folds=15, accuracy=0.631 (0.570,0.684)\n",
      "> folds=16, accuracy=0.622 (0.580,0.663)\n",
      "> folds=17, accuracy=0.627 (0.573,0.651)\n",
      "> folds=18, accuracy=0.632 (0.595,0.680)\n",
      "> folds=19, accuracy=0.624 (0.581,0.685)\n",
      "> folds=20, accuracy=0.625 (0.573,0.698)\n",
      "> folds=21, accuracy=0.622 (0.577,0.676)\n",
      "> folds=22, accuracy=0.624 (0.582,0.698)\n",
      "> folds=23, accuracy=0.623 (0.594,0.680)\n",
      "> folds=24, accuracy=0.613 (0.565,0.667)\n",
      "> folds=25, accuracy=0.623 (0.566,0.669)\n",
      "> folds=26, accuracy=0.631 (0.581,0.692)\n",
      "> folds=27, accuracy=0.622 (0.569,0.693)\n",
      "> folds=28, accuracy=0.627 (0.564,0.719)\n",
      "> folds=29, accuracy=0.626 (0.567,0.672)\n",
      "> folds=30, accuracy=0.626 (0.548,0.690)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # create the dataset\n",
    "# def get_dataset(n_samples=100):\n",
    "#     X = pd.DataFrame(train_X_s)\n",
    "#     y = EV_intention_df['bichoice']\n",
    "#     return X, y\n",
    " \n",
    "# retrieve the model to be evaluate\n",
    "def get_model():\n",
    "    model = DecisionTreeClassifier()\n",
    "    return model\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv):\n",
    " # get the dataset\n",
    "   # X = pd.DataFrame(train_X_s)\n",
    "    y = EV_intention_df['bichoice']\n",
    "    model = get_model()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    " \n",
    "# calculate the ideal test condition\n",
    "ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "print('Ideal: %.3f' % ideal)\n",
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs = list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model(cv)\n",
    "    # report performance\n",
    "    print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "# line plot of k mean values with min/max error bars\n",
    "pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xf/jx9r80jx6939hwd0mqxjrfzr0000gn/T/ipykernel_82601/626675244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# calculate the ideal test condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mideal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeaveOneOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ideal: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mideal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# define folds to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xf/jx9r80jx6939hwd0mqxjrfzr0000gn/T/ipykernel_82601/626675244.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(cv)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# return scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # create the dataset\n",
    "# def get_dataset(n_samples=100):\n",
    "#     X = pd.DataFrame(train_X_s)\n",
    "#     y = EV_intention_df['bichoice']\n",
    "#     return X, y\n",
    " \n",
    "# retrieve the model to be evaluate\n",
    "def get_model():\n",
    "    model = RandomForestClassifier()\n",
    "    return model\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv):\n",
    " # get the dataset\n",
    "    X = pd.DataFrame(train_X_s )\n",
    "    y = EV_intention_df['bichoice']\n",
    "    model = get_model()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    " \n",
    "# calculate the ideal test condition\n",
    "ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "print('Ideal: %.3f' % ideal)\n",
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs = list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model(cv)\n",
    "    # report performance\n",
    "    print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "# line plot of k mean values with min/max error bars\n",
    "pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fy/806wf8pn3kz3h6dk5ysytsjr0000gn/T/ipykernel_7604/258170382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# calculate the ideal test condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mideal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeaveOneOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ideal: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mideal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# define folds to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fy/806wf8pn3kz3h6dk5ysytsjr0000gn/T/ipykernel_7604/258170382.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(cv)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_X_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# return scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # create the dataset\n",
    "# def get_dataset(n_samples=100):\n",
    "#     X = pd.DataFrame(train_X_s)\n",
    "#     y = EV_intention_df['bichoice']\n",
    "#     return X, y\n",
    " \n",
    "# retrieve the model to be evaluate\n",
    "def get_model():\n",
    "    model = XGBClassifier()\n",
    "    return model\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv):\n",
    " # get the dataset\n",
    "    #X = pd.DataFrame(train_X_s)\n",
    "    y = EV_intention_df['bichoice']\n",
    "    model = get_model()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, full_X_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    " \n",
    "# calculate the ideal test condition\n",
    "ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "print('Ideal: %.3f' % ideal)\n",
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs = list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model(cv)\n",
    "    # report performance\n",
    "    print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "# line plot of k mean values with min/max error bars\n",
    "pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal: 0.742\n",
      "> folds=2, accuracy=0.700 (0.691,0.709)\n",
      "> folds=3, accuracy=0.719 (0.712,0.726)\n",
      "> folds=4, accuracy=0.723 (0.711,0.731)\n",
      "> folds=5, accuracy=0.728 (0.718,0.740)\n",
      "> folds=6, accuracy=0.728 (0.702,0.750)\n",
      "> folds=7, accuracy=0.735 (0.701,0.758)\n",
      "> folds=8, accuracy=0.728 (0.703,0.761)\n",
      "> folds=9, accuracy=0.739 (0.718,0.769)\n",
      "> folds=10, accuracy=0.739 (0.722,0.766)\n",
      "> folds=11, accuracy=0.737 (0.706,0.759)\n",
      "> folds=12, accuracy=0.734 (0.697,0.768)\n",
      "> folds=13, accuracy=0.737 (0.692,0.788)\n",
      "> folds=14, accuracy=0.738 (0.697,0.791)\n",
      "> folds=15, accuracy=0.738 (0.685,0.771)\n",
      "> folds=16, accuracy=0.736 (0.704,0.775)\n",
      "> folds=17, accuracy=0.734 (0.692,0.790)\n",
      "> folds=18, accuracy=0.738 (0.683,0.787)\n",
      "> folds=19, accuracy=0.742 (0.695,0.800)\n",
      "> folds=20, accuracy=0.741 (0.692,0.800)\n",
      "> folds=21, accuracy=0.743 (0.698,0.786)\n",
      "> folds=22, accuracy=0.742 (0.694,0.791)\n",
      "> folds=23, accuracy=0.741 (0.672,0.797)\n",
      "> folds=24, accuracy=0.746 (0.687,0.812)\n",
      "> folds=25, accuracy=0.741 (0.686,0.801)\n",
      "> folds=26, accuracy=0.739 (0.681,0.819)\n",
      "> folds=27, accuracy=0.740 (0.676,0.813)\n",
      "> folds=28, accuracy=0.737 (0.668,0.795)\n",
      "> folds=29, accuracy=0.741 (0.655,0.793)\n",
      "> folds=30, accuracy=0.742 (0.680,0.797)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # create the dataset\n",
    "# def get_dataset(n_samples=100):\n",
    "#     X = pd.DataFrame(train_X_s)\n",
    "#     y = EV_intention_df['bichoice']\n",
    "#     return X, y\n",
    " \n",
    "# retrieve the model to be evaluate\n",
    "def get_model():\n",
    "    model = LGBMClassifier()\n",
    "    return model\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv):\n",
    " # get the dataset\n",
    "    X = pd.DataFrame(train_X_s)\n",
    "    y = EV_intention_df['bichoice']\n",
    "    model = get_model()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    " \n",
    "# calculate the ideal test condition\n",
    "ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "print('Ideal: %.3f' % ideal)\n",
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs = list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model(cv)\n",
    "    # report performance\n",
    "    print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "# line plot of k mean values with min/max error bars\n",
    "pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process LokyProcess-45:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 483, in _process_worker\n",
      "    gc.collect()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xf/jx9r80jx6939hwd0mqxjrfzr0000gn/T/ipykernel_82601/738509655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# evaluate model using each test condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mcv_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mideal_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mideal_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;31m# check for invalid results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mideal_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xf/jx9r80jx6939hwd0mqxjrfzr0000gn/T/ipykernel_82601/738509655.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(cv, model)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEV_intention_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bichoice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;31m# return scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# correlation between test harness and ideal test condition\n",
    "from numpy import mean\n",
    "from numpy import isnan\n",
    "from numpy import asarray\n",
    "from numpy import polyfit\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    " \n",
    "# # create the dataset\n",
    "# def get_dataset(n_samples=100):\n",
    "#  X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "#  return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression())\n",
    "#  models.append(RidgeClassifier())\n",
    "#  models.append(SGDClassifier())\n",
    "#  models.append(PassiveAggressiveClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "#  models.append(ExtraTreeClassifier())\n",
    "#  models.append(LinearSVC())\n",
    "#  models.append(SVC())\n",
    "#  models.append(GaussianNB())\n",
    "#  models.append(AdaBoostClassifier())\n",
    "#  models.append(BaggingClassifier())\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(XGBClassifier())\n",
    "    models.append(LGBMClassifier())\n",
    "#     models.append(DecisionTreeClassifier())\n",
    "\n",
    "#  models.append(ExtraTreesClassifier())\n",
    "#  models.append(GaussianProcessClassifier())\n",
    "#  models.append(GradientBoostingClassifier())\n",
    "#  models.append(LinearDiscriminantAnalysis())\n",
    "#  models.append(QuadraticDiscriminantAnalysis())\n",
    "    return models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    " # get the dataset\n",
    "    X = pd.DataFrame(train_X_s)\n",
    "    y = EV_intention_df['bichoice']\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores)\n",
    " \n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "        # store results\n",
    "        cv_results.append(cv_mean)\n",
    "        ideal_results.append(ideal_mean)\n",
    "        # summarize progress\n",
    "        print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "pyplot.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "pyplot.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "pyplot.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
    "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
